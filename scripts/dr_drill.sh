#!/usr/bin/env bash
#
# dr_drill.sh ‚Äì Disaster‚ÄëRecovery (DR) validation drill
#
# What it does (high‚Äëlevel):
#   1Ô∏è‚É£ Stop the primary PostgreSQL container (citadel-db)
#   2Ô∏è‚É£ Spin a temporary PostgreSQL container to act as the restore target
#   3Ô∏è‚É£ Pull the latest base backup (tar.gz) from S3 and extract it
#   4Ô∏è‚É£ Replay WAL files for the last N hours (default 24h) using pg_receivewal
#   5Ô∏è‚É£ Verify the restored data matches the original snapshot (sha256 checksum)
#   6Ô∏è‚É£ Bring the primary DB back up
#
# Exit codes:
#   0 ‚Äì DR drill completed successfully
#   1 ‚Äì Fatal error (preconditions not met, or drill failed)
#
# Usage:
#   ./dr_drill.sh                          # Use default configuration
#   WAL_HOURS=12 ./dr_drill.sh             # Replay only 12 hours of WAL
#   DRY_RUN=true ./dr_drill.sh             # Show what would be executed (no-op)
#
# Requirements:
#   * aws CLI (configured with credentials for S3 access)
#   * docker (for container operations)
#   * sha256sum (for checksum verification)
#   * docker-compose.yml (present in current directory)
#
# Environment variables:
#   DRY_RUN                     ‚Äì if true, only prints actions (default: false)
#   RESTORE_CONTAINER_NAME      ‚Äì name of temporary restore container (default: pg_restore)
#   RESTORE_DATA_DIR            ‚Äì local directory for restore data (default: dr_restore)
#   BASE_BACKUP_S3_PREFIX       ‚Äì S3 prefix for base backups (default: citadel-audit/backup)
#   WAL_S3_PREFIX               ‚Äì S3 prefix for WAL files (default: citadel-audit/wal)
#   WAL_HOURS                   ‚Äì hours of WAL to replay (default: 24)
#   POSTGRES_IMAGE              ‚Äì Docker image for restore container (default: postgres:15)
#   POSTGRES_PASSWORD           ‚Äì password for restore container (default: secret)
#   POSTGRES_USER               ‚Äì username for restore container (default: postgres)
#
# ======================================================================

set -euo pipefail   # fail fast on errors, undefined vars, pipe failures

# ---- Default values (override with env vars) -------------------------
DRY_RUN=${DRY_RUN:-false}
RESTORE_CONTAINER_NAME=${RESTORE_CONTAINER_NAME:-pg_restore}
RESTORE_DATA_DIR=${RESTORE_DATA_DIR:-dr_restore}
BASE_BACKUP_S3_PREFIX=${BASE_BACKUP_S3_PREFIX:-citadel-audit/backup}
WAL_S3_PREFIX=${WAL_S3_PREFIX:-citadel-audit/wal}
WAL_HOURS=${WAL_HOURS:-24}
POSTGRES_IMAGE=${POSTGRES_IMAGE:-postgres:15}
POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-secret}
POSTGRES_USER=${POSTGRES_USER:-postgres}

# =====================================================================
# Helper functions
# ‚úÖ FIXED: All functions now have explicit return statements
# =====================================================================

log() {
    echo -e "$(date '+%Y-%m-%d %H:%M:%S') [DR-DRILL] $*"
    return 0
}

die() {
    log "ERROR: $*" >&2
    return 1
}

# =====================================================================
# Helper: run a command unless we are in dry‚Äërun mode
# ‚úÖ FIXED: Added explicit return statement
# =====================================================================
run() {
    if [[ "$DRY_RUN" == "true" ]]; then
        log "[DRY‚ÄëRUN] $*"
        return 0
    else
        eval "$@"
        return $?
    fi
}

# =====================================================================
# 0Ô∏è‚É£ Sanity checks
# =====================================================================
log "Performing pre-flight checks‚Ä¶"

if ! command -v aws &> /dev/null; then
    die "aws CLI not found ‚Äì please install the AWS CLI"
    exit 1
fi

if ! command -v docker &> /dev/null; then
    die "docker not found ‚Äì please install Docker"
    exit 1
fi

if ! command -v sha256sum &> /dev/null; then
    die "sha256sum not found ‚Äì please install coreutils"
    exit 1
fi

# Ensure we are in the repo root (where docker‚Äëcompose.yml lives)
if [[ ! -f docker-compose.yml ]]; then
    die "docker-compose.yml not found ‚Äì run this script from the repo root"
    exit 1
fi

log "‚úÖ All pre-flight checks passed."

# =====================================================================
# 1Ô∏è‚É£ Stop the primary DB (citadel-db)
# =====================================================================
log "Stopping primary PostgreSQL container (citadel-db)‚Ä¶"
run docker compose stop citadel-db

# =====================================================================
# 2Ô∏è‚É£ Spin up a temporary restore container (detached)
# =====================================================================
log "Launching temporary restore container [$RESTORE_CONTAINER_NAME]‚Ä¶"
run docker run -d --name "$RESTORE_CONTAINER_NAME" \
    -e POSTGRES_PASSWORD="$POSTGRES_PASSWORD" \
    -e POSTGRES_USER="$POSTGRES_USER" \
    -v "$(pwd)/$RESTORE_DATA_DIR:/var/lib/postgresql/data" \
    "$POSTGRES_IMAGE"

# Wait for the container to be healthy (Postgres starts)
log "Waiting for restore container to become ready (max 30 s)‚Ä¶"
if ! timeout 30 bash -c "
    while ! docker exec \"$RESTORE_CONTAINER_NAME\" pg_isready -U \"$POSTGRES_USER\" >/dev/null 2>&1; do
        sleep 1
    done
"; then
    die "Restore container did not become ready within 30 seconds"
    exit 1
fi
log "‚úÖ Restore container is up."

# =====================================================================
# 3Ô∏è‚É£ Pull the latest base backup from S3 and extract it
# =====================================================================
log "Fetching latest base backup from S3‚Ä¶"
LATEST_BACKUP=$(aws s3 ls "s3://$BASE_BACKUP_S3_PREFIX/" | sort | tail -n1 | awk '{print $4}')

if [[ -z "$LATEST_BACKUP" ]]; then
    die "No backup files found in s3://$BASE_BACKUP_S3_PREFIX/"
    exit 1
fi

log "Downloading $LATEST_BACKUP ‚Ä¶"
run aws s3 cp "s3://$BASE_BACKUP_S3_PREFIX/$LATEST_BACKUP" - \| tar -xz -C "$RESTORE_DATA_DIR"

# Verify that the extracted directory now contains a PG_VERSION file
if [[ ! -f "$RESTORE_DATA_DIR/PG_VERSION" ]]; then
    die "Extraction failed ‚Äì PG_VERSION not found in $RESTORE_DATA_DIR"
    exit 1
fi

PG_VERSION=$(cat "$RESTORE_DATA_DIR/PG_VERSION")
log "‚úÖ Base backup extracted (PostgreSQL version $PG_VERSION)."

# =====================================================================
# 4Ô∏è‚É£ Replay WAL files for the last $WAL_HOURS hours
# =====================================================================
log "Replaying WAL files for the last $WAL_HOURS hour(s)‚Ä¶"

# Create (or reuse) a replication slot named restore_slot
run docker exec "$RESTORE_CONTAINER_NAME" pg_create_physical_replication_slot -U "$POSTGRES_USER" restore_slot \|\| true

# Pull WAL files from S3 ‚Äì we assume they are stored with filenames like 0000000100000000000000A1
# We'll download only those whose modification time is within the last $WAL_HOURS.
WAL_TMP=$(mktemp -d)
log "Downloading recent WAL files to $WAL_TMP ‚Ä¶"
run aws s3 sync "s3://$WAL_S3_PREFIX" "$WAL_TMP" --exclude "*" \
    --include "*" \
    --exact-timestamps \
    --no-progress

# Filter files newer than $WAL_HOURS ago
cutoff_epoch=$(date -d "-$WAL_HOURS hours" +%s)
wal_files=()

while IFS= read -r -d '' file; do
    mod_epoch=$(stat -c %Y "$file")
    if (( mod_epoch >= cutoff_epoch )); then
        wal_files+=("$file")
    fi
done < <(find "$WAL_TMP" -type f -print0)

if [[ ${#wal_files[@]} -eq 0 ]]; then
    die "No WAL files found for the last $WAL_HOURS hour(s)."
    exit 1
fi

log "Found ${#wal_files[@]} WAL segments ‚Äì feeding to pg_receivewal‚Ä¶"

# Feed each WAL segment to the restore container
for wal in "${wal_files[@]}"; do
    wal_basename=$(basename "$wal")
    run docker cp "$wal" "$RESTORE_CONTAINER_NAME:/tmp/$wal_basename"
    run docker exec "$RESTORE_CONTAINER_NAME" pg_receivewal -D /var/lib/postgresql/data \
        --slot=restore_slot \
        --create-slot \
        --endpos=LATEST \
        --walfile="/tmp/$wal_basename"
done

log "‚úÖ WAL replay completed."

# =====================================================================
# 5Ô∏è‚É£ Verify checksum vs. original snapshot
# =====================================================================
log "Computing checksum of restored PG_VERSION‚Ä¶"
RESTORE_CHECKSUM=$(sha256sum "$RESTORE_DATA_DIR/PG_VERSION" | awk '{print $1}')

log "Fetching original checksum from S3 (stored alongside the backup)‚Ä¶"
BACKUP_NAME_WITHOUT_EXT="${LATEST_BACKUP%.*}"
ORIG_CHECKSUM=$(aws s3 cp "s3://$BASE_BACKUP_S3_PREFIX/$BACKUP_NAME_WITHOUT_EXT.sha256" - 2>/dev/null || true)

if [[ -z "$ORIG_CHECKSUM" ]]; then
    log "‚ö†Ô∏è  No original checksum file found ‚Äì skipping verification."
else
    log "Original checksum: $ORIG_CHECKSUM"
    log "Restored checksum: $RESTORE_CHECKSUM"
    if [[ "$ORIG_CHECKSUM" == "$RESTORE_CHECKSUM" ]]; then
        log "‚úÖ Checksums match ‚Äì restore appears consistent."
    else
        log "‚ùå Checksums differ! Restored data may be corrupt."
    fi
fi

# =====================================================================
# 6Ô∏è‚É£ Bring the primary DB back up
# =====================================================================
log "Bringing primary PostgreSQL container back up‚Ä¶"
run docker compose start citadel-db

# =====================================================================
# Optional: clean up the temporary restore container and data dir
# =====================================================================
log "Cleaning up temporary restore resources‚Ä¶"
run docker rm -f "$RESTORE_CONTAINER_NAME"
run rm -rf "$RESTORE_DATA_DIR"

# Clean up temp WAL directory
if [[ -d "$WAL_TMP" ]]; then
    run rm -rf "$WAL_TMP"
fi

log "üü¢ DR‚Äëdrill completed successfully."
exit 0
