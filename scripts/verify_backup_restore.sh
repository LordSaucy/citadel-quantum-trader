#!/usr/bin/env bash
# -------------------------------------------------
# verify_backup_restore.sh
#   ‚Ä¢ Takes the newest nightly pg_dump (custom format) from S3
#   ‚Ä¢ Restores it into a temporary PostgreSQL instance
#   ‚Ä¢ Compares row‚Äëcounts and a sample of recent trades
#   ‚Ä¢ Measures total elapsed time (RTO) and data‚Äëloss % (RPO)
# -------------------------------------------------
set -euo pipefail

# ------------ CONFIG -------------------------------------------------
S3_BUCKET="s3://citadel-audit/backup"
TMP_DIR="/tmp/citadel_restore_$$"
RESTORE_CONTAINER="citadel-restore-test"
SOURCE_CONTAINER="citadel-db"
DB_USER="citadel"
DB_NAME="citadel"
# How many recent rows to sample for a deeper check (0 = skip)
SAMPLE_SIZE=20
# -------------------------------------------------
mkdir -p "${TMP_DIR}"
cd "${TMP_DIR}"

# 1Ô∏è‚É£ Grab the newest backup file from S3
echo "üì• Downloading latest backup from ${S3_BUCKET} ..."
LATEST_OBJ=$(aws s3 ls "${S3_BUCKET}/" | sort | tail -n1 | awk '{print $4}')
if [[ -z "${LATEST_OBJ}" ]]; then
  echo "‚ùå No backup objects found in ${S3_BUCKET}"
  exit 1
fi
aws s3 cp "${S3_BUCKET}/${LATEST_OBJ}" "./backup.dump"
echo "‚úÖ Downloaded ${LATEST_OBJ}"

# 2Ô∏è‚É£ Record start time
START_TS=$(date +%s)

# 3Ô∏è‚É£ Restore into the temporary DB
echo "üîÑ Restoring backup into container ${RESTORE_CONTAINER} ..."
docker exec -i "${RESTORE_CONTAINER}" pg_restore \
  --no-owner \
  --no-acl \
  --dbname="${DB_NAME}" \
  --username="${DB_USER}" \
  --jobs=$(nproc) \
  ./backup.dump > restore.log 2>&1

# 4Ô∏è‚É£ Record end time and compute RTO
END_TS=$(date +%s)
RTO_SEC=$((END_TS - START_TS))
echo "‚è±Ô∏è  Restore completed in ${RTO_SEC}s"

# 5Ô∏è‚É£ Row‚Äëcount comparison
SRC_COUNT=$(docker exec "${SOURCE_CONTAINER}" psql -U "${DB_USER}" -d "${DB_NAME}" -t -c "SELECT COUNT(*) FROM trades;")
TGT_COUNT=$(docker exec "${RESTORE_CONTAINER}" psql -U "${DB_USER}" -d "${DB_NAME}" -t -c "SELECT COUNT(*) FROM trades;")
echo "üî¢ Source row count: ${SRC_COUNT}"
echo "üî¢ Target row count: ${TGT_COUNT}"

# 6Ô∏è‚É£ Compute RPO (percentage of rows lost)
if [[ "${SRC_COUNT}" -eq 0 ]]; then
  RPO_PCT=0
else
  LOST=$((SRC_COUNT - TGT_COUNT))
  RPO_PCT=$(awk "BEGIN {printf \"%.4f\", (${LOST}/${SRC_COUNT})*100}")
fi
echo "üìâ Data‚Äëloss (RPO) = ${RPO_PCT}% (lost ${LOST} rows)"

# 7Ô∏è‚É£ Sample recent trades (optional but recommended)
if (( SAMPLE_SIZE > 0 )); then
  echo "üîé Sampling the most recent ${SAMPLE_SIZE} trades from each DB ..."
  SRC_SAMPLE=$(docker exec "${SOURCE_CONTAINER}" psql -U "${DB_USER}" -d "${DB_NAME}" \
    -t -c "SELECT id, ts, bucket_id, pnl FROM trades ORDER BY ts DESC LIMIT ${SAMPLE_SIZE};")
  TGT_SAMPLE=$(docker exec "${RESTORE_CONTAINER}" psql -U "${DB_USER}" -d "${DB_NAME}" \
    -t -c "SELECT id, ts, bucket_id, pnl FROM trades ORDER BY ts DESC LIMIT ${SAMPLE_SIZE};")

  # Compare line‚Äëby‚Äëline (order matters because we sorted by ts)
  DIFF=$(diff <(echo "${SRC_SAMPLE}") <(echo "${TGT_SAMPLE}") || true)
  if [[ -z "${DIFF}" ]]; then
    echo "‚úÖ Sampled trades match exactly."
  else
    echo "‚ö†Ô∏è  Sampled trades differ!"
    echo "${DIFF}"
  fi
fi

# 8Ô∏è‚É£ Final pass/fail logic
PASS=true
if (( RTO_SEC > 300 )); then   # 5‚ÄØmin = 300‚ÄØs
  echo "‚ùå RTO exceeds 5‚ÄØmin (got ${RTO_SEC}s)."
  PASS=false
fi
if (( $(awk "BEGIN {print (${RPO_PCT}>1)}") )); then
  echo "‚ùå RPO exceeds 1‚ÄØ% (got ${RPO_PCT}%)."
  PASS=false
fi

if $PASS; then
  echo "üéâ BACKUP‚ÄëRESTORE VERIFICATION PASSED."
  exit 0
else
  echo "üö® BACKUP‚ÄëRESTORE VERIFICATION FAILED."
  exit 1
fi
