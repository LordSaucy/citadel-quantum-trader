#!/usr/bin/env python3
"""
run_shadow.py

Launches the Citadel stack in SHADOW mode, runs for a configurable
duration (or until a trade count is reached), stops the stack,
and then compares the shadow log against the paperâ€‘trading log.
"""

import argparse
import json
import subprocess
import sys
import time
from datetime import datetime, timedelta
from pathlib import Path

import pandas as pd
import requests

# -----------------------------------------------------------------
# Configuration (adjust as needed)
# -----------------------------------------------------------------
PROMETHEUS_URL = "http://localhost:9090/api/v1/query"
BOT_HEALTH_URL = "http://localhost:8000/health"
METRIC_POLL_INTERVAL = 30          # seconds
MAX_TRADE_COUNT = 500
MAX_DURATION = timedelta(hours=48)  # 48â€¯h

def wait_for_bot(timeout: int = 120) -> bool:
    deadline = time.time() + timeout
    while time.time() < deadline:
        try:
            r = requests.get(BOT_HEALTH_URL, timeout=5)
            if r.ok and r.json().get("status") == "ok":
                return True
        except Exception:
            pass
        time.sleep(2)
    return False

def prom_query(expr: str) -> float:
    resp = requests.get(PROMETHEUS_URL, params={"query": expr})
    resp.raise_for_status()
    data = resp.json()
    if data["status"] != "success" or not data["data"]["result"]:
        return 0.0
    return float(data["data"]["result"][0]["value"][1])

def main() -> int:
    parser = argparse.ArgumentParser(
        description="Run a Shadow (liveâ€‘mirror, noâ€‘capital) campaign"
    )
    parser.add_argument(
        "--compose",
        default="docker-compose.yml",
        help="Base compose file (default: docker-compose.yml)",
    )
    parser.add_argument(
        "--override",
        default="docker-compose.shadow.yml",
        help="Shadowâ€‘mode override file",
    )
    args = parser.parse_args()

    # -------------------------------------------------------------
    # 1ï¸âƒ£  Start the Docker stack (shadow mode)
    # -------------------------------------------------------------
    print("ðŸš€ Starting Shadow stack â€¦")
    up_cmd = [
        "docker",
        "compose",
        "-f",
        args.compose,
        "-f",
        args.override,
        "up",
        "-d",
    ]
    subprocess.check_call(up_cmd)

    # -------------------------------------------------------------
    # 2ï¸âƒ£  Wait for health endpoint
    # -------------------------------------------------------------
    print("â³ Waiting for bot health â€¦")
    if not wait_for_bot():
        print("âŒ Bot never became healthy â€“ aborting", file=sys.stderr)
        subprocess.run(
            ["docker", "compose", "-f", args.compose, "-f", args.override, "down"]
        )
        return 1

    print("âœ… Bot is healthy â€“ monitoring metrics â€¦")

    # -------------------------------------------------------------
    # 3ï¸âƒ£  Monitoring loop (same as paperâ€‘trading)
    # -------------------------------------------------------------
    start_time = datetime.now()
    trade_counter = 0
    max_latency = 0.0
    total_rejects = 0
    total_slip = 0.0
    slip_samples = 0

    while True:
        latency = prom_query('max(cqt_order_latency_seconds{shadow="yes"})')
        max_latency = max(max_latency, latency)

        rejects = prom_query('sum(cqt_orders_total{shadow="yes", success="false"})')
        total_rejects = int(rejects)

        slip = prom_query('avg(cqt_order_slippage_pips{shadow="yes"})')
        if slip > 0:
            total_slip += slip
            slip_samples += 1

        trade_counter = int(prom_query('sum(cqt_orders_total{shadow="yes"})'))

        elapsed = datetime.now() - start_time
        if trade_counter >= MAX_TRADE_COUNT:
            print(f"ðŸ Reached {trade_counter} shadow trades â€“ stopping")
            break
        if elapsed >= MAX_DURATION:
            print(f"âŒ› 48â€¯h elapsed ({elapsed}) â€“ stopping")
            break

        time.sleep(METRIC_POLL_INTERVAL)

    # -------------------------------------------------------------
    # 4ï¸âƒ£  Shut down the stack
    # -------------------------------------------------------------
    print("ðŸ›‘ Stopping Docker stack â€¦")
    subprocess.run(
        ["docker", "compose", "-f", args.compose, "-f", args.override, "down"]
    )

    # -------------------------------------------------------------
      # -------------------------------------------------------------
    # 5ï¸âƒ£  Pull the shadow log (mounted inside the container at
    #      /var/log/cqt_shadow.log) and compare it with the
    #      paperâ€‘trading log (mounted at /var/log/cqt_paper.log)
    # -------------------------------------------------------------
    print("ðŸ“‚ Retrieving shadow log â€¦")
    shadow_log_host_path = Path("/tmp/cqt_shadow.log")
    paper_log_host_path  = Path("/tmp/cqt_paper.log")

    # The Dockerâ€‘Compose file mounts the host directory `./logs` into the
    # container at `/var/log`.  We therefore copy the files from the
    # container to a temporary location on the host.
    try:
        # Shadow container name is `cqt-engine` (same as in compose)
        subprocess.check_call([
            "docker", "cp",
            "cqt-engine:/var/log/cqt_shadow.log",
            str(shadow_log_host_path)
        ])
        subprocess.check_call([
            "docker", "cp",
            "cqt-engine:/var/log/cqt_paper.log",
            str(paper_log_host_path)
        ])
    except subprocess.CalledProcessError as exc:
        print(f"âš ï¸  Could not retrieve logs: {exc}", file=sys.stderr)
        return 2

    # -------------------------------------------------------------
    # 6ï¸âƒ£  Load both logs, turn them into DataFrames and compute stats
    # -------------------------------------------------------------
    print("ðŸ”Ž Analysing logs â€¦")
    try:
        shadow_df = process_log(shadow_log_host_path)
        paper_df  = process_log(paper_log_host_path)
    except Exception as exc:
        print(f"âŒ Failed to parse logs: {exc}", file=sys.stderr)
        return 3

    # Basic sanity check â€“ both logs should contain the same columns
    common_cols = set(shadow_df.columns) & set(paper_df.columns)
    if not common_cols:
        print("âš ï¸  No overlapping columns between logs â€“ cannot compare.", file=sys.stderr)
        return 4

    # -----------------------------------------------------------------
    # Helper to compute a few key metrics from a DataFrame
    # -----------------------------------------------------------------
    def summarize(df: pd.DataFrame, label: str) -> Dict[str, float]:
        """Return a dict of aggregated metrics for printing."""
        # We assume the log contains at least:
        #   - timestamp (ISO string)
        #   - latency_seconds (float)
        #   - success (bool/int)
        #   - slippage_pips (float, optional)
        #   - reject_reason (string, optional)
        out = {}
        if "latency_seconds" in df:
            out["avg_latency"] = df["latency_seconds"].mean()
            out["max_latency"] = df["latency_seconds"].max()
        if "success" in df:
            successes = df["success"].astype(bool).sum()
            total     = len(df)
            out["win_rate"] = successes / total * 100 if total else 0.0
        if "slippage_pips" in df:
            out["avg_slip"] = df["slippage_pips"].mean()
        if "reject_reason" in df:
            out["rejects"] = df["reject_reason"].notna().sum()
        # Add a label for pretty printing
        out["label"] = label
        return out

    shadow_stats = summarize(shadow_df, "SHADOW")
    paper_stats  = summarize(paper_df,  "PAPER ")

    # -----------------------------------------------------------------
    # Prettyâ€‘print a sideâ€‘byâ€‘side comparison table
    # -----------------------------------------------------------------
    def fmt(v: Any) -> str:
        return f"{v:.2f}" if isinstance(v, (int, float)) else str(v)

    headers = ["Metric", "Shadow", "Paper", "Î” (Shadowâ€‘Paper)"]
    rows = []
    metric_keys = set(shadow_stats) | set(paper_stats)
    metric_keys.discard("label")   # we already know the labels

    for key in sorted(metric_keys):
        s_val = shadow_stats.get(key, 0.0)
        p_val = paper_stats.get(key, 0.0)
        delta = s_val - p_val
        rows.append([key, fmt(s_val), fmt(p_val), fmt(delta)])

    col_widths = [max(len(str(cell)) for cell in col) for col in zip(*([headers] + rows))]
    line_fmt = " | ".join(f"{{:{w}}}" for w in col_widths)

    print("\n=== Shadow vs. Paperâ€‘Trading Summary ===")
    print(line_fmt.format(*headers))
    print("-" * (sum(col_widths) + 3 * (len(col_widths) - 1)))
    for row in rows:
        print(line_fmt.format(*row))

    # -------------------------------------------------------------
    # 7ï¸âƒ£  Exit code â€“ 0 = success, >0 = something went wrong
    # -------------------------------------------------------------
    print("\nâœ… Shadow run completed.")
    return 0


# -----------------------------------------------------------------
# Helper: read a log file where each line is a JSON object.
# -----------------------------------------------------------------
def process_log(path: Path) -> pd.DataFrame:
    """
    Parse a lineâ€‘delimited JSON log file into a pandas DataFrame.

    Expected fields (all optional â€“ missing columns are ignored):
        - timestamp (ISOâ€‘8601 string)
        - latency_seconds (float)
        - success (bool/int)
        - slippage_pips (float)
        - reject_reason (string)

    Returns:
        pandas.DataFrame with one row per log entry.
    """
    records = []
    with path.open("r", encoding="utf-8") as fh:
        for line_no, line in enumerate(fh, start=1):
            line = line.strip()
            if not line:
                continue
            try:
                rec = json.loads(line)
                records.append(rec)
            except json.JSONDecodeError as exc:
                raise ValueError(f"Invalid JSON on line {line_no} of {path}: {exc}")

    if not records:
        return pd.DataFrame()   # empty DataFrame

    df = pd.DataFrame.from_records(records)

    # Normalise column names (some code may emit camelCase)
    df.rename(columns=lambda c: c.lower().replace("-", "_"), inplace=True)

    # Ensure proper dtypes where possible
    if "timestamp" in df:
        df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")
    if "success" in df:
        df["success"] = df["success"].astype(bool)
    if "latency_seconds" in df:
        df["latency_seconds"] = pd.to_numeric(df["latency_seconds"], errors="coerce")
    if "slippage_pips" in df:
        df["slippage_pips"] = pd.to_numeric(df["slippage_pips"], errors="coerce")

    return df


# -----------------------------------------------------------------
# Entryâ€‘point guard
# -----------------------------------------------------------------
if __name__ == "__main__":
    sys.exit(main())
