version: '3.9'

# =====================================================================
# CITADEL QUANTUM TRADER - STANDBY ENGINE (HOT FAILOVER)
# =====================================================================
# VPS: voc-g-2c-8gb-50s (2 vCPU, 8GB RAM, 50GB SSD)
# Location: Virginia (different region for HA)
# Cost: $72/mo
#
# Containers:
#  1. citadel-quantum-trader (standby mode - read-only)
#  2. PostgreSQL 14 (streaming replica from Primary)
#  3. Redis (replica from Primary)
#  4. pgBouncer (connection pooling)
#  5. Keepalived (failover monitor)
#
# Replication: Streaming from Primary (< 1 second lag)
# Failover: Automatic (< 30 seconds)
#
# =====================================================================

services:
  # ===================================================================
  # CITADEL QUANTUM TRADER ENGINE (STANDBY MODE)
  # ===================================================================
  engine:
    image: citadel-quantum-trader:latest
    container_name: cqt_engine_standby
    restart: always
    networks:
      - trading
    ports:
      - "8000:8000"
    environment:
      # ---- Application Configuration ----
      ENV: production
      LOG_LEVEL: info
      DEPLOYMENT_MODE: standby
      STANDBY_ROLE: hot_standby
      
      # ---- Database Configuration (Read-Only) ----
      DATABASE_URL: postgresql://cqt_user:${DB_PASSWORD}@pgbouncer:6432/citadel_trades
      DATABASE_POOL_SIZE: 20
      DATABASE_MAX_OVERFLOW: 10
      DATABASE_READONLY: "true"
      
      # ---- Redis Configuration (Replica) ----
      REDIS_URL: redis://redis:6379/0
      REDIS_MODE: replica
      REDIS_READONLY: "true"
      
      # ---- Broker Configuration (LIVE MODE - ready for failover) ----
      MT5_MODE: live
      MT5_BROKER: ${MT5_BROKER}
      MT5_LOGIN: ${MT5_LOGIN}
      MT5_PASSWORD: ${MT5_PASSWORD}
      MT5_SERVER: ${MT5_SERVER}
      
      IBKR_ENV: live
      IBKR_ACCOUNT: ${IBKR_ACCOUNT}
      IBKR_API_KEY: ${IBKR_API_KEY}
      
      # ---- Trading Configuration ----
      RISK_FRACTION: ${RISK_FRACTION:-0.01}
      MAX_LOSS_PER_DAY: ${MAX_LOSS_PER_DAY:-0.05}
      
      # ---- Kill-Switch Configuration ----
      CQT_KILL_SWITCH: "1"
      
      # ---- Monitoring ----
      PROMETHEUS_ENABLED: "true"
      PROMETHEUS_PORT: 8001
      
      # ---- Network Configuration ----
      API_HOST: 0.0.0.0
      API_PORT: 8000
      
      # ---- Replication (Standby) ----
      REPLICATION_MODE: standby
      PRIMARY_VPS_IP: ${PRIMARY_VPS_IP}
      PRIMARY_VPS_PORT: 5432
      REPLICATION_SLOT_NAME: standby_replica
      
      # ---- Failover Configuration ----
      FAILOVER_ENABLED: "true"
      FAILOVER_HEALTHCHECK_INTERVAL: 5
      FAILOVER_TIMEOUT: 30
      PROMOTE_TO_PRIMARY_ON_FAILURE: "true"
      
    volumes:
      - engine_logs:/app/logs
      - engine_cache:/app/cache
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      pgbouncer:
        condition: service_started
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"

  # ===================================================================
  # POSTGRESQL 14 (STREAMING REPLICA FROM PRIMARY)
  # ===================================================================
  postgres:
    image: postgres:14-alpine
    container_name: cqt_postgres_standby
    restart: always
    networks:
      - trading
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: cqt_user
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: citadel_trades
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - postgres_wal:/var/lib/postgresql/wal
      - ./standby_recovery.conf:/var/lib/postgresql/recovery.conf
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U cqt_user -d citadel_trades"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    command:
      - "postgres"
      - "-c"
      - "wal_level=replica"
      - "-c"
      - "max_wal_senders=3"
      - "-c"
      - "wal_keep_size=1GB"
      - "-c"
      - "hot_standby=on"
      - "-c"
      - "hot_standby_feedback=on"
      - "-c"
      - "recovery_target_timeline=latest"
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # ===================================================================
  # PGBOUNCER (CONNECTION POOLING - STANDBY)
  # ===================================================================
  pgbouncer:
    image: pgbouncer:latest
    container_name: cqt_pgbouncer_standby
    restart: always
    networks:
      - trading
    ports:
      - "6432:6432"
    environment:
      DATABASES_HOST: postgres
      DATABASES_PORT: 5432
      DATABASES_USER: cqt_user
      DATABASES_PASSWORD: ${DB_PASSWORD}
      DATABASES_DBNAME: citadel_trades
      PGBOUNCER_POOL_MODE: transaction
      PGBOUNCER_MAX_CLIENT_CONN: 1000
      PGBOUNCER_DEFAULT_POOL_SIZE: 25
      PGBOUNCER_MIN_POOL_SIZE: 10
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "psql", "-U", "cqt_user", "-d", "citadel_trades", "-c", "SELECT 1"]
      interval: 10s
      timeout: 5s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # ===================================================================
  # REDIS (REPLICA - Synced from Primary)
  # ===================================================================
  redis:
    image: redis:7-alpine
    container_name: cqt_redis_standby
    restart: always
    networks:
      - trading
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - ./redis-standby.conf:/usr/local/etc/redis/redis.conf
    command:
      - redis-server
      - /usr/local/etc/redis/redis.conf
      - --slaveof
      - ${PRIMARY_VPS_IP}
      - "6379"
      - --slave-read-only
      - "yes"
      - --appendonly
      - "yes"
      - --maxmemory
      - "2gb"
      - --maxmemory-policy
      - "allkeys-lru"
    healthcheck:
      test: ["CMD", "redis-cli", "PING"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # ===================================================================
  # KEEPALIVED (AUTOMATIC FAILOVER MONITOR)
  # ===================================================================
  keepalived:
    image: keepalived:latest
    container_name: cqt_keepalived
    restart: always
    networks:
      - trading
    environment:
      VRRP_INTERFACE: eth0
      VRRP_VIRTUAL_IP: ${VIRTUAL_IP}
      VRRP_ROUTER_ID: 51
      VRRP_PRIORITY: 100
      VRRP_ADVERT_INT: 1
      PRIMARY_IP: ${PRIMARY_VPS_IP}
      STANDBY_IP: ${STANDBY_VPS_IP}
    volumes:
      - ./keepalived.conf:/etc/keepalived/keepalived.conf
    cap_add:
      - NET_ADMIN
      - NET_BROADCAST
    healthcheck:
      test: ["CMD", "keepalived", "--version"]
      interval: 30s
      timeout: 5s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # ===================================================================
  # PROMETHEUS (METRICS SCRAPING) - Optional on Standby
  # ===================================================================
  prometheus:
    image: prom/prometheus:latest
    container_name: cqt_prometheus_standby
    restart: always
    networks:
      - trading
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus-standby.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--storage.tsdb.retention.time=7d"
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

networks:
  trading:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

volumes:
  postgres_data:
    driver: local
  postgres_wal:
    driver: local
  redis_data:
    driver: local
  engine_logs:
    driver: local
  engine_cache:
    driver: local
  prometheus_data:
    driver: local
