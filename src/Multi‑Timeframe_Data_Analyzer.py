#!/usr/bin/env python3
"""
Multi‚ÄëTimeframe Data Analyzer

Loads MT5‚Äëexported CSVs (M15, H1, H4, D1, W1) and the alignment
matrix generated by the MT5 script.  Provides:

* Trend‚Äëalignment scoring
* Identification of the best alignment periods
* Helpers for back‚Äëtesting / strategy optimisation
* Prometheus gauges for live monitoring
* A tiny Flask API (GET /summary, GET /alignment, POST /config) so
  Grafana can read or change parameters in real time.

Author: Lawful Banker
Created: 2024‚Äë11‚Äë26
"""

# ----------------------------------------------------------------------
# Standard library
# ----------------------------------------------------------------------
import json
import logging
import os
from datetime import datetime, timedelta
from pathlib import Path
from threading import Event, Thread
from time import sleep
from typing import Dict, List, Optional, Tuple

# ----------------------------------------------------------------------
# Third‚Äëparty
# ----------------------------------------------------------------------
import pandas as pd
import numpy as np
from flask import Flask, jsonify, request, abort   # pip install flask
from prometheus_client import Gauge                # already a dependency

# ----------------------------------------------------------------------
# Logging
# ----------------------------------------------------------------------
logger = logging.getLogger(__name__)

# ----------------------------------------------------------------------
# Helper ‚Äì Prometheus gauge registration (one per configurable key)
# ----------------------------------------------------------------------
def _make_gauge(name: str, description: str) -> Gauge:
    """Factory that creates a gauge with a ``parameter`` label."""
    return Gauge(
        f"mtf_{name}",
        description,
        ["parameter"],
    )

# ----------------------------------------------------------------------
# Main Analyzer class
# ----------------------------------------------------------------------
class MTFDataAnalyzer:
    """
    Loads and analyses MT5 multi‚Äëtimeframe CSV exports.

    Public API used by the rest of the trading system:

    * ``load_all_data()`` ‚Äì pulls CSVs into pandas DataFrames.
    * ``should_trade_now(direction, min_alignment)`` ‚Äì quick alignment check.
    * ``get_best_alignment_periods(min_score, min_duration_hours)`` ‚Äì returns
      a list of high‚Äëquality periods.
    * ``get_summary()`` ‚Äì human‚Äëreadable text for logs / UI.
    * ``export_alignment_summary(path)`` ‚Äì JSON dump for offline analysis.
    """

    # ------------------------------------------------------------------
    # Default tunables (exposed via the Flask API & Prometheus)
    # ------------------------------------------------------------------
    DEFAULTS = {
        "min_total_score": 95.0,          # overall score needed to trade
        "min_alignment_score": 70.0,      # alignment % threshold
        "min_period_hours": 4,            # shortest period we care about
        "debug": False,                   # extra logging
    }

    # ------------------------------------------------------------------
    # Prometheus gauges (one per tunable)
    # ------------------------------------------------------------------
    _gauges: Dict[str, Gauge] = {
        key: _make_gauge(key, f"Tunable parameter `{key}` for MTF analyzer")
        for key in DEFAULTS
    }

    # ------------------------------------------------------------------
    def __init__(self, data_prefix: str = "mtf_data", symbol: str = "EURUSD"):
        """
        Initialise the analyzer.

        Args:
            data_prefix: Prefix of the CSV files produced by the MT5 script.
            symbol:      Trading symbol (e.g. EURUSD).
        """
        self.data_prefix = data_prefix
        self.symbol = symbol
        self.mt5_files_path = self._find_mt5_files_path()

        # DataFrames for each timeframe ‚Äì will be filled by load_all_data()
        self.m15: Optional[pd.DataFrame] = None
        self.h1:  Optional[pd.DataFrame] = None
        self.h4:  Optional[pd.DataFrame] = None
        self.d1:  Optional[pd.DataFrame] = None
        self.w1:  Optional[pd.DataFrame] = None
        self.alignment: Optional[pd.DataFrame] = None

        # Runtime‚Äëmutable configuration (starts with defaults)
        self.config: Dict[str, float] = self.DEFAULTS.copy()

        # Load persisted config if it exists
        self._load_persisted_config()

        # Initialise Prometheus gauges with current values
        for k, g in self._gauges.items():
            g.labels(parameter=k).set(self.config[k])

        logger.info("üìä MTF Data Analyzer initialised")
        logger.info(f"   Symbol: {self.symbol}")
        logger.info(f"   Data prefix: {self.data_prefix}")

    # ------------------------------------------------------------------
    # 0Ô∏è‚É£  Configuration persistence (JSON on disk)
    # ------------------------------------------------------------------
    _CONFIG_PATH = Path("/app/config/mtf_analyzer_config.json")   # mounted volume

    def _load_persisted_config(self) -> None:
        """Read JSON config from disk if present, otherwise keep defaults."""
        if self._CONFIG_PATH.exists():
            try:
                with open(self._CONFIG_PATH, "r") as f:
                    persisted = json.load(f)
                # Only keep keys we recognise
                for k, v in persisted.items():
                    if k in self.DEFAULTS:
                        self.config[k] = float(v)
                logger.info(f"Loaded persisted MTF config from {self._CONFIG_PATH}")
            except Exception as exc:   # pragma: no cover
                logger.error(f"Failed to read persisted config: {exc}")

    def _persist_config(self) -> None:
        """Write current config to disk (called after any change)."""
        try:
            self._CONFIG_PATH.parent.mkdir(parents=True, exist_ok=True)
            with open(self._CONFIG_PATH, "w") as f:
                json.dump(self.config, f, indent=2)
        except Exception as exc:   # pragma: no cover
            logger.error(f"Could not persist MTF config: {exc}")

    # ------------------------------------------------------------------
    # 1Ô∏è‚É£  Find MT5 Files directory (where the CSVs live)
    # ------------------------------------------------------------------
    def _find_mt5_files_path(self) -> Optional[str]:
        """Locate the MT5 `Files` folder (used by the MQL5 exporter)."""
        possible_paths = [
            os.path.join(os.environ.get('APPDATA', ''), 'MetaQuotes', 'Terminal'),
            r"C:\Users\Administrator\AppData\Roaming\MetaQuotes\Terminal",
            r"C:\Program Files\MetaTrader 5\MQL5\Files",
        ]

        for base_path in possible_paths:
            if os.path.isdir(base_path):
                # Terminal folders contain sub‚Äëfolders per installation
                if 'Terminal' in base_path:
                    for folder in os.listdir(base_path):
                        candidate = os.path.join(base_path, folder, 'MQL5', 'Files')
                        if os.path.isdir(candidate):
                            return candidate
                else:
                    return base_path
        return None

    # ------------------------------------------------------------------
    # 2Ô∏è‚É£  Load CSV helpers
    # ------------------------------------------------------------------
    def _find_csv_file(self, filename: str) -> Optional[str]:
        """Search for a CSV in several locations (local, MT5 Files, cwd)."""
        # 1Ô∏è‚É£ Direct path (absolute or relative to cwd)
        if os.path.isfile(filename):
            return filename

        # 2Ô∏è‚É£ MT5 Files folder
        if self.mt5_files_path:
            candidate = os.path.join(self.mt5_files_path, filename)
            if os.path.isfile(candidate):
                return candidate

        # 3Ô∏è‚É£ Current working directory
        cwd_candidate = os.path.join(os.getcwd(), filename)
        if os.path.isfile(cwd_candidate):
            return cwd_candidate

        return None

    def _load_timeframe(self, tf: str) -> bool:
        """Load a single timeframe CSV into a DataFrame."""
        filename = f"{self.data_prefix}_{self.symbol}_{tf}.csv"
        csv_path = self._find_csv_file(filename)
        if not csv_path:
            logger.warning(f"‚ö†Ô∏è {tf} data not found: {filename}")
            return False

        try:
            df = pd.read_csv(csv_path)
            df['datetime'] = pd.to_datetime(df['datetime'])
            df.set_index('datetime', inplace=True)
            setattr(self, tf.lower(), df)
            logger.info(f"‚úÖ Loaded {tf}: {len(df)} rows")
            return True
        except Exception as exc:
            logger.error(f"‚ùå Error loading {tf}: {exc}")
            return False

    def _load_alignment(self) -> bool:
        """Load the alignment CSV generated by the MT5 script."""
        filename = f"{self.data_prefix}_{self.symbol}_alignment.csv"
        csv_path = self._find_csv_file(filename)
        if not csv_path:
            logger.warning("‚ö†Ô∏è Alignment CSV not found")
            return False

        try:
            df = pd.read_csv(csv_path)
            df['datetime'] = pd.to_datetime(df['datetime'])
            df.set_index('datetime', inplace=True)
            self.alignment = df
            logger.info(f"‚úÖ Alignment data loaded ({len(df)} rows)")
            return True
        except Exception as exc:
            logger.error(f"‚ùå Error loading alignment CSV: {exc}")
            return False

    # ------------------------------------------------------------------
    # 3Ô∏è‚É£  Public loader ‚Äì attempts all timeframes + alignment
    # ------------------------------------------------------------------
    def load_all_data(self) -> bool:
        """
        Load all timeframe CSVs and the alignment file.

        Returns:
            True if at least one timeframe was loaded successfully.
        """
        loaded = 0
        for tf in ['M15', 'H1', 'H4', 'D1', 'W1']:
            if self._load_timeframe(tf):
                loaded += 1

        self._load_alignment()
        if loaded:
            logger.info(f"‚úÖ Successfully loaded {loaded} timeframe(s)")
            return True
        else:
            logger.error("‚ùå No timeframe data could be loaded")
            return False

    # ------------------------------------------------------------------
    # 4Ô∏è‚É£  Alignment helpers
    # ------------------------------------------------------------------
    def get_alignment_at_time(self, timestamp: datetime) -> Optional[Dict]:
        """
        Return the alignment row nearest to ``timestamp``.
        """
        if self.alignment is None:
            logger.warning("‚ö†Ô∏è Alignment data not loaded")
            return None

        idx = self.alignment.index.searchsorted(timestamp)
        if idx >= len(self.alignment):
            idx = len(self.alignment) - 1
        row = self.alignment.iloc[idx]

        return {
            'timestamp': row.name,
            'm15_trend': row.get('m15_trend', 'NEUTRAL'),
            'h1_trend': row.get('h1_trend', 'NEUTRAL'),
            'h4_trend': row.get('h4_trend', 'NEUTRAL'),
            'd1_trend': row.get('d1_trend', 'NEUTRAL'),
            'alignment_score': row.get('alignment_score', 0.0),
            'primary_trend': row.get('primary_trend', 'NEUTRAL'),
            'trend_strength': row.get('trend_strength', 0.0),
        }

    def should_trade_now(self, direction: str,
                         min_alignment: Optional[float] = None) -> Tuple[bool, str, float]:
        """
        Quick check whether the current alignment supports a trade.

        Args:
            direction: "BUY" or "SELL".
            min_alignment: Override the configured threshold.

        Returns:
            (should_trade, reason, alignment_score)
        """
        if self.alignment is None:
            return False, "No alignment data", 0.0

        latest = self.alignment.iloc[-1]
        score = float(latest['alignment_score'])
        primary = latest.get('primary_trend', 'NEUTRAL')

        # Use overridden threshold if supplied, otherwise config
        threshold = min_alignment if min_alignment is not None else self.config["min_alignment_score"]

        if primary != direction:
            return False, f"Primary trend {primary} ‚â† {direction}", score
        if score < threshold:
            return False, f"Alignment {score:.1f}% < {threshold}%", score
        return True, f"Alignment {score:.1f}% meets threshold", score

    # ------------------------------------------------------------------
    # 5Ô∏è‚É£  Best‚Äëperiod discovery
    # ------------------------------------------------------------------
    def get_best_alignment_periods(self,
                                  min_score: Optional[float] = None,
                                  min_duration_hours: Optional[int] = None) -> List[Dict]:
        """
        Identify contiguous periods where the alignment score stays above
        ``min_score`` for at least ``min_duration_hours``.
        """
        if self.alignment is None:
            logger.warning("‚ö†Ô∏è Alignment data not loaded")
            return []

        min_score = min_score if min_score is not None else self.config["min_alignment_score"]
        min_duration = min_duration_hours if min_duration_hours is not None else self.config["min_period_hours"]

        # Filter rows meeting the score threshold
        high = self.alignment[self.alignment['alignment_score'] >= min_score].copy()
        if high.empty:
            return []

        periods = []
        cur = None

        for ts, row in high.iterrows():
            if cur is None:
                cur = {
                    'start': ts,
                    'end': ts,
                    'avg_score': row['alignment_score'],
                    'bars': 1,
                    'primary_trend': row.get('primary_trend', 'NEUTRAL')
                }
                continue

            # Consecutive if gap ‚â§ 2‚ÄØh (adjustable if you wish)
            gap = (ts - cur['end']).total_seconds() / 3600.0
            if gap <= 2:
                cur['end'] = ts
                cur['avg_score'] = (cur['avg_score'] * cur['bars'] + row['alignment_score']) / (cur['bars'] + 1)
                cur['bars'] += 1
            else:
                # finalize previous period
                duration = (cur['end'] - cur['start']).total_seconds() / 3600.0
                if duration >= min_duration:
                    periods.append({
                        'start': cur['start'],
                        'end': cur['end'],
                        'duration_h': round(duration, 1),
                        'avg_score': round(cur['avg_score'], 1),
                        'primary_trend': cur['primary_trend']
                    })
                # start new period
                cur = {
                    'start': ts,
                    'end': ts,
                    'avg_score': row['alignment_score'],
                    'bars': 1,
                    'primary_trend': row.get('primary_trend', 'NEUTRAL')
                }

        # Append the final period
        if cur:
            duration = (cur['end'] - cur['start']).total_seconds() / 3600.0
            if duration >= min_duration:
                periods.append({
                    'start': cur['start'],
                    'end': cur['end'],
                    'duration_h': round(duration, 1),
                    'avg_score': round(cur['avg_score'], 1),
                    'primary_trend': cur['primary_trend']
                })

        # Sort by average score descending
        periods.sort(key=lambda p: p['avg_score'], reverse=True)
        return periods

    # ------------------------------------------------------------------
    # 6Ô∏è‚É£  Timeframe data accessor (with optional date slicing)
    # ------------------------------------------------------------------
    def get_timeframe_data(self,
                           timeframe: str,
                           start: Optional[datetime] = None,
                           end: Optional[datetime] = None) -> Optional[pd.DataFrame]:
        """
        Return the DataFrame for a given timeframe, optionally sliced by dates.
        """
        df = getattr(self, timeframe.lower(), None)
        if df is None:
            logger.warning(f"‚ö†Ô∏è {timeframe} data not loaded")
            return None

        if start or end:
            return df.loc[start:end]
        return df

    # ------------------------------------------------------------------
    # 7Ô∏è‚É£  Export / summary helpers
    # ------------------------------------------------------------------
    def export_alignment_summary(self,
                                 output_path: str = "mtf_alignment_summary.json") -> bool:
        """Write a JSON file summarising the alignment dataset."""
        if self.alignment is None:
            logger.error("No alignment data to export")
            return False

        try:
            summary = {
                'symbol': self.symbol,
                'generated_at': datetime.now().isoformat(),
                'total_rows': len(self.alignment),
                'overall': {
                    'avg_score': float(self.alignment['alignment_score'].mean()),
                    'max_score': float(self.alignment['alignment_score'].max()),
                    'min_score': float(self.alignment['alignment_score'].min()),
                    'high_score_pct': float(
                        (self.alignment['alignment_score'] >= 70).mean() * 100
                    )
                },
                'trend_distribution': {
                    'BUY': float((self.alignment['primary_trend'] == 'BUY').mean() * 100),
                    'SELL': float((self.alignment['primary_trend'] == 'SELL').mean() * 100),
                    'NEUTRAL': float((self.alignment['primary_trend'] == 'NEUTRAL').mean() * 100)
                },
                'best_periods': self.get_best_alignment_periods(min_score=80.0)[:10]
            }

            # Convert timestamps to ISO strings for JSON friendliness
            for p in summary['best_periods']:
                p['start'] = p['start'].isoformat()
                p['end'] = p['end'].isoformat()

            Path(output_path).parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, "w") as f:
                json.dump(summary, f, indent=2, default=str)

            logger.info(f"‚úÖ Alignment summary exported to {output_path}")
            return True
        except Exception as exc:
            logger.error(f"‚ùå Failed to export summary: {exc}")
            return False

    def get_summary(self) -> str:
        """Human‚Äëreadable multi‚Äëline summary (good for logs or UI)."""
        lines = ["‚ïê" * 70,
                 "       MULTI‚ÄëTIMEFRAME DATA ANALYZER SUMMARY",
                 "‚ïê" * 70,
                 f"Symbol: {self.symbol}",
                 f"Data prefix: {self.data_prefix}",
                 ""]

        # Timeframe overview
        lines.append("üìà Loaded Timeframes:")
        for tf in ['M15', 'H1', 'H4', 'D1', 'W1']:
            df = getattr(self, tf.lower())
            if df is not None:
                lines.append(f"  {tf}: {len(df):,} rows ({df.index[0]} ‚Üí {df.index[-1]})")
            else:
                lines.append(f"  {tf}: NOT LOADED")

        # Alignment overview
       # --------------------------------------------------------------
        # Alignment overview (if data is present)
        # --------------------------------------------------------------
        if self.alignment is not None:
            lines.append("")
            lines.append("üß≠ Alignment Data:")
            lines.append(f"  Rows          : {len(self.alignment):,}")
            lines.append(f"  Avg score (%) : {self.alignment['alignment_score'].mean():.1f}")
            lines.append(f"  Max score (%) : {self.alignment['alignment_score'].max():.1f}")
            lines.append(f"  Min score (%) : {self.alignment['alignment_score'].min():.1f}")
            high_pct = (self.alignment['alignment_score'] >= 70).mean() * 100
            lines.append(f"  ‚â•70‚ÄØ% score   : {high_pct:.1f}% of rows")

            # Trend distribution
            lines.append("")
            lines.append("üìä Primary Trend Distribution:")
            total = len(self.alignment)
            buy_cnt = (self.alignment['primary_trend'] == 'BUY').sum()
            sell_cnt = (self.alignment['primary_trend'] == 'SELL').sum()
            neut_cnt = (self.alignment['primary_trend'] == 'NEUTRAL').sum()
            lines.append(f"  BUY      : {buy_cnt:,} ({buy_cnt/total*100:.1f}%)")
            lines.append(f"  SELL     : {sell_cnt:,} ({sell_cnt/total*100:.1f}%)")
            lines.append(f"  NEUTRAL  : {neut_cnt:,} ({neut_cnt/total*100:.1f}%)")

            # Best periods (top 3)
            best = self.get_best_alignment_periods(min_score=80.0)
            if best:
                lines.append("")
                lines.append("üèÜ Top Alignment Periods (score‚ÄØ‚â•‚ÄØ80‚ÄØ%):")
                for i, p in enumerate(best[:3], 1):
                    dur = p['duration_h']
                    lines.append(
                        f"  {i}. {p['start'].strftime('%Y-%m-%d %H:%M')} ‚Äì "
                        f"{p['end'].strftime('%H:%M')} | "
                        f"{dur:.1f}‚ÄØh | {p['avg_score']:.1f}% | {p['primary_trend']}"
                    )
        else:
            lines.append("")
            lines.append("‚ö†Ô∏è No alignment data loaded")

        lines.append("")
        lines.append("‚ïê" * 70)
        return "\n".join(lines)

    # ------------------------------------------------------------------
    # 8Ô∏è‚É£  Configuration handling (runtime‚Äëtunable)
    # ------------------------------------------------------------------
    def set_config(self, key: str, value: float) -> None:
        """
        Update a tunable configuration value at runtime.

        The change is persisted to disk, the corresponding Prometheus gauge
        is updated, and a log entry is emitted.
        """
        if key not in self.config:
            raise KeyError(f"Unknown config key: {key}")

        try:
            self.config[key] = float(value)
            # Update Prometheus gauge
            self._gauges[key].labels(parameter=key).set(self.config[key])
            self._persist_config()
            logger.info(f"Config updated ‚Äì {key} = {self.config[key]}")
        except Exception as exc:   # pragma: no cover
            logger.error(f"Failed to set config {key}: {exc}")
            raise

    def get_config(self, key: Optional[str] = None):
        """Return a copy of the whole config or a single key."""
        if key is None:
            return self.config.copy()
        if key not in self.config:
            raise KeyError(f"Unknown config key: {key}")
        return self.config[key]

    # ------------------------------------------------------------------
    # 9Ô∏è‚É£  Flask API ‚Äì runs in a background daemon thread
    # ------------------------------------------------------------------
    def _start_api(self, host: str = "0.0.0.0", port: int = 5006) -> None:
        """
        Spin up a tiny Flask server exposing:

        * GET  /summary          ‚Üí multi‚Äëline human readable summary
        * GET  /config           ‚Üí JSON of all tunable parameters
        * GET  /config/<key>    ‚Üí single parameter value
        * POST /config/<key>    ‚Üí JSON body { "value": <float> } to update
        * GET  /healthz          ‚Üí simple health check
        """
        app = Flask(__name__)

        @app.route("/summary", methods=["GET"])
        def summary():
            return "<pre>" + self.get_summary() + "</pre>"

        @app.route("/config", methods=["GET"])
        def config_all():
            return jsonify(self.get_config())

        @app.route("/config/<key>", methods=["GET"])
        def config_one(key):
            try:
                return jsonify({key: self.get_config(key)})
            except KeyError:
                abort(404, description=f"Config key {key} not found")

        @app.route("/config/<key>", methods=["POST", "PUT", "PATCH"])
        def config_update(key):
            if key not in self.config:
                abort(404, description=f"Config key {key} not found")
            payload = request.get_json(force=True)
            if not payload or "value" not in payload:
                abort(400, description="JSON body must contain 'value'")
            try:
                self.set_config(key, payload["value"])
                return jsonify({key: self.get_config(key)})
            except Exception as exc:   # pragma: no cover
                abort(500, description=str(exc))

        @app.route("/healthz", methods=["GET"])
        def health():
            return "OK", 200

        def _run():
            # Flask's built‚Äëin server is sufficient for internal use.
            app.run(host=host, port=port, debug=False, use_reloader=False)

        Thread(target=_run, daemon=True, name="mtf-analyzer-api").start()
        logger.info(f"üì° Flask API for MTF analyzer listening on {host}:{port}")

    # ------------------------------------------------------------------
    # 10Ô∏è‚É£  Graceful shutdown helper (called from the main process)
    # ------------------------------------------------------------------
    def stop(self):
        """Placeholder for future clean‚Äëup ‚Äì currently nothing to stop."""
        pass


# ----------------------------------------------------------------------
# Global singleton ‚Äì importable from other modules (e.g. src/main.py)
# ----------------------------------------------------------------------
mtf_analyzer = MTFDataAnalyzer()

# ----------------------------------------------------------------------
# If this file is executed directly, run a quick demo / sanity check
# ----------------------------------------------------------------------
def _demo():
    """Simple interactive demo ‚Äì useful during development."""
    logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")
    logger.info("=== MTF Data Analyzer Demo ===")

    if not mtf_analyzer.load_all_data():
        logger.error("Failed to load any data ‚Äì aborting demo")
        return

    # Print a nice summary
    print(mtf_analyzer.get_summary())

    # Show current config
    print("\nCurrent tunable parameters:")
    for k, v in mtf_analyzer.get_config().items():
        print(f"  {k}: {v}")

    # Example: check if we should trade BUY right now
    ok, reason, score = mtf_analyzer.should_trade_now("BUY")
    print(f"\nShould we BUY now? {'YES' if ok else 'NO'} ‚Äì {reason} (score {score:.1f}%)")

    # Export alignment summary JSON
    mtf_analyzer.export_alignment_summary()

    # Start the Flask API (will keep the process alive)
    mtf_analyzer._start_api()

    # Keep the script alive so the API can be queried
    try:
        while True:
            sleep(60)
    except KeyboardInterrupt:
        logger.info("Demo interrupted ‚Äì exiting")
        mtf_analyzer.stop()


if __name__ == "__main__":
    _demo()
