#!/usr/bin/env python3
"""
Candlestick Statistics Analyzer

Analyzes MT5‚Äëgenerated candlestick statistics and provides optimal
Stop‚ÄëLoss / Take‚ÄëProfit recommendations.  The analyser is completely
self‚Äëcontained, persists its configuration, and can be queried from the
trading engine in real time.

Features
--------
* Loads the CSV file produced by the MQL5 ‚ÄúCandlestickAnalysisReport.mq5‚Äù.
* Parses overall, hourly, daily and volatility‚Äësegmented statistics.
* Calculates a dynamic SL distance (pips) based on average range,
  volatility state and a safety buffer.
* Returns a full SL/TP dictionary (prices, pips, R:R, confidence, etc.).
* Offers helper methods for:
    ‚Äì Best trading hours
    ‚Äì Position‚Äësize volatility adjustment
    ‚Äì Human‚Äëreadable summary
    ‚Äì JSON export for downstream consumption
* Persists the raw CSV location and can be re‚Äëloaded on demand.
"""

# ----------------------------------------------------------------------
# Standard library
# ----------------------------------------------------------------------
import json
import logging
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

# ----------------------------------------------------------------------
# Third‚Äëparty
# ----------------------------------------------------------------------
import numpy as np
import pandas as pd

# ----------------------------------------------------------------------
# Logging
# ----------------------------------------------------------------------
logger = logging.getLogger(__name__)

# ----------------------------------------------------------------------
# Main analyser class
# ----------------------------------------------------------------------
class CandlestickAnalyzer:
    """
    Core analyser ‚Äì loads the CSV, parses it into convenient dictionaries
    and provides SL/TP recommendations based on the current hour and
    volatility regime.
    """

    # ------------------------------------------------------------------
    def __init__(self, csv_path: str = "candlestick_stats.csv"):
        """
        Initialise the analyser.

        Args:
            csv_path: Relative or absolute path to the CSV file that the
                      MT5 script writes to.  If the file is not found the
                      analyser will fall back to a safe default.
        """
        self.csv_path = csv_path
        self.df: Optional[pd.DataFrame] = None

        # Parsed containers
        self.overall_stats: Optional[Dict] = None
        self.hourly_stats: Dict[str, Dict] = {}
        self.daily_stats: Dict[str, Dict] = {}
        self.volatility_stats: Dict[str, Dict] = {}

        # Resolve the MT5 ‚ÄúFiles‚Äù folder (used when the CSV lives there)
        self.mt5_files_path = self._find_mt5_files_path()

        logger.info("üìä Candlestick Analyzer initialised")
        logger.info(f"   CSV path: {self.csv_path}")

    # ------------------------------------------------------------------
    # 0Ô∏è‚É£  Locate the MT5 ‚ÄúFiles‚Äù directory (Windows only)
    # ------------------------------------------------------------------
    def _find_mt5_files_path(self) -> Optional[str]:
        """Search common locations for the MT5 ‚ÄúFiles‚Äù folder."""
        possible_paths = [
            os.path.join(os.environ.get("APPDATA", ""), "MetaQuotes", "Terminal"),
            r"C:\Users\Administrator\AppData\Roaming\MetaQuotes\Terminal",
            r"C:\Program Files\MetaTrader 5\MQL5\Files",
        ]

        for base_path in possible_paths:
            if not os.path.isdir(base_path):
                continue

            # Terminal directories contain a random GUID folder ‚Äì dive in
            if "Terminal" in base_path:
                for folder in os.listdir(base_path):
                    candidate = os.path.join(base_path, folder, "MQL5", "Files")
                    if os.path.isdir(candidate):
                        return candidate
            else:
                return base_path

        return None

    # ------------------------------------------------------------------
    # 1Ô∏è‚É£  Locate the CSV file (multiple fallback locations)
    # ------------------------------------------------------------------
    def _find_csv_file(self) -> Optional[str]:
        """Return the absolute path to the CSV, or None if not found."""
        # 1Ô∏è‚É£  Absolute / relative path as‚Äëgiven
        if os.path.isfile(self.csv_path):
            return self.csv_path

        # 2Ô∏è‚É£  Inside the MT5 ‚ÄúFiles‚Äù folder
        if self.mt5_files_path:
            candidate = os.path.join(self.mt5_files_path, self.csv_path)
            if os.path.isfile(candidate):
                return candidate

        # 3Ô∏è‚É£  Current working directory (useful when running locally)
        cwd_candidate = os.path.join(os.getcwd(), self.csv_path)
        if os.path.isfile(cwd_candidate):
            return cwd_candidate

        return None

    # ------------------------------------------------------------------
    # 2Ô∏è‚É£  Load the CSV into a pandas DataFrame
    # ------------------------------------------------------------------
    def load_statistics(self) -> bool:
        """
        Load candlestick statistics from the CSV file.

        Returns:
            True  ‚Äì CSV successfully loaded and parsed
            False ‚Äì CSV not found or parsing error
        """
        csv_file = self._find_csv_file()
        if not csv_file:
            logger.error(f"‚ùå Candlestick stats CSV not found: {self.csv_path}")
            return False

        try:
            self.df = pd.read_csv(csv_file)
            self._parse_statistics()
            logger.info("‚úÖ Loaded candlestick statistics")
            logger.info(f"   Categories: {len(self.df['category'].unique())}")
            logger.info(f"   Total rows: {len(self.df)}")
            return True
        except Exception as exc:   # pragma: no cover
            logger.error(f"‚ùå Error loading statistics: {exc}")
            return False

    # ------------------------------------------------------------------
    # 3Ô∏è‚É£  Split the raw DataFrame into handy dictionaries
    # ------------------------------------------------------------------
    def _parse_statistics(self) -> None:
        """Populate overall, hourly, daily and volatility dictionaries."""
        if self.df is None:
            return

        # ----- Overall ----------------------------------------------------
        overall = self.df[self.df["category"] == "OVERALL"]
        if not overall.empty:
            self.overall_stats = overall.iloc[0].to_dict()

        # ----- Hourly -----------------------------------------------------
        hourly = self.df[self.df["category"] == "HOUR"]
        for _, row in hourly.iterrows():
            self.hourly_stats[row["subcategory"]] = row.to_dict()

        # ----- Daily ------------------------------------------------------
        daily = self.df[self.df["category"] == "DAY"]
        for _, row in daily.iterrows():
            self.daily_stats[row["subcategory"]] = row.to_dict()

        # ----- Volatility -------------------------------------------------
        vol = self.df[self.df["category"] == "VOLATILITY"]
        for _, row in vol.iterrows():
            self.volatility_stats[row["subcategory"]] = row.to_dict()

    # ------------------------------------------------------------------
    # 4Ô∏è‚É£  Helper ‚Äì pick the most appropriate stats bucket
    # ------------------------------------------------------------------
    def _get_applicable_stats(self, hour: int, volatility_state: str) -> Dict:
        """
        Return the statistics dict that best matches the current context.

        Preference order:
            1Ô∏è‚É£  Volatility bucket (LOW / NORMAL / HIGH)
            2Ô∏è‚É£  Hourly bucket (e.g. ‚Äú13:00‚Äë13:59‚Äù)
            3Ô∏è‚É£  Overall stats (fallback)
        """
        # 1Ô∏è‚É£  Volatility
        if volatility_state.upper() in self.volatility_stats:
            return self.volatility_stats[volatility_state.upper()]

        # 2Ô∏è‚É£  Hourly ‚Äì format must match exactly the CSV subcategory
        hour_key = f"{hour:02d}:00-{hour:02d}:59"
        if hour_key in self.hourly_stats:
            return self.hourly_stats[hour_key]

        # 3Ô∏è‚É£  Overall fallback
        return self.overall_stats or {}

    # ------------------------------------------------------------------
    # 5Ô∏è‚É£  Core SL distance calculation (pips)
    # ------------------------------------------------------------------
    def _calculate_sl_distance(self, stats: Dict, volatility_state: str) -> float:
        """
        Derive a sensible SL distance (in pips) from the supplied stats.

        Strategy
        --------
        * Base SL = average total range * 1.2  (20‚ÄØ% safety buffer)
        * Adjust for volatility:
            ‚Äì HIGH   ‚Üí √ó‚ÄØ1.5  (wider SL)
            ‚Äì LOW    ‚Üí √ó‚ÄØ0.8  (tighter SL)
            ‚Äì NORMAL ‚Üí √ó‚ÄØ1.0
        * Enforce a minimum of 15‚ÄØpips.
        """
        avg_range = stats.get("total_range_avg_pips", 30)
        base_sl = avg_range * 1.2

        # Volatility multiplier
        if volatility_state.upper() == "HIGH":
            mult = 1.5
        elif volatility_state.upper() == "LOW":
            mult = 0.8
        else:
            mult = 1.0

        sl = base_sl * mult
        sl = max(sl, 15)          # never tighter than 15‚ÄØpips
        return round(sl, 1)

    # ------------------------------------------------------------------
    # 6Ô∏è‚É£  Public API ‚Äì optimal SL/TP for a given trade
    # ------------------------------------------------------------------
    def get_optimal_sl_tp(
        self,
        symbol: str,
        direction: str,
        entry_price: float,
        current_hour: Optional[int] = None,
        volatility_state: str = "NORMAL",
        risk_reward_ratio: float = 2.0,
    ) -> Dict:
        """
        Calculate optimal SL/TP based on the loaded statistics.

        Args:
            symbol: Instrument ticker (e.g. ‚ÄúEURUSD‚Äù)
            direction: ‚ÄúBUY‚Äù or ‚ÄúSELL‚Äù
            entry_price: Desired entry price
            current_hour: Hour of day (0‚Äë23).  If omitted, uses now().
            volatility_state: ‚ÄúLOW‚Äù, ‚ÄúNORMAL‚Äù or ‚ÄúHIGH‚Äù.
            risk_reward_ratio: Desired R:R (default 2‚ÄØ:‚ÄØ1).

        Returns:
            dict with keys:
                - sl_price, tp_price (price levels)
                - sl_pips, tp_pips (distance in pips)
                - risk_reward_ratio
                - based_on (human readable description)
                - avg_range_pips (for diagnostics)
                - confidence (HIGH / MODERATE / LOW)
        """
        if self.overall_stats is None:
            logger.warning("‚ö†Ô∏è No statistics loaded ‚Äì falling back to defaults")
            return self._default_sl_tp(entry_price, direction)

        # Resolve hour if not supplied
        if current_hour is None:
            current_hour = datetime.now().hour

        # Grab the most relevant stats bucket
        stats = self._get_applicable_stats(current_hour, volatility_state)

        # Compute SL distance (pips) and derive TP
        sl_pips = self._calculate_sl_distance(stats, volatility_state)
        tp_pips = sl_pips * risk_reward_ratio

        # Pip size depends on the instrument (JPY pairs have 0.01)
        pip_size = 0.0001
        if "JPY" in symbol.upper():
            pip_size = 0.01

        if direction.upper() == "BUY":
            sl_price = entry_price - sl_pips * pip_size
            tp_price = entry_price + tp_pips * pip_size
        else:   # SELL
            sl_price = entry_price + sl_pips * pip_size
            tp_price = entry_price - tp_pips * pip_size

        return {
            "sl_price": round(sl_price, 5),
            "tp_price": round(tp_price, 5),
            "sl_pips": sl_pips,
            "tp_pips": tp_pips,
            "risk_reward_ratio": risk_reward_ratio,
            "based_on": f"{volatility_state.title()} volatility, hour {current_hour}",
            "avg_range_pips": stats.get("total_range_avg_pips", 0),
            "confidence": "HIGH" if len(self.hourly_stats) > 20 else "MODERATE",
        }

    # ------------------------------------------------------------------
    # 7Ô∏è‚É£  Fallback SL/TP when no statistics are available
    # ------------------------------------------------------------------
    def _default_sl_tp(self, entry_price: float, direction: str) -> Dict:
        """Very safe default ‚Äì 30‚ÄØpips SL, 60‚ÄØpips TP (1‚ÄØ:‚ÄØ2)."""
        logger.warning("‚ö†Ô∏è Using default SL/TP (no statistics)")
        sl_pips = 30
        tp_pips = 60
        pip_size = 0.0001
        if direction.upper() == "SELL" and "JPY" in str(entry_price):
            pip_size = 0.01

        if direction.upper() == "BUY":
            sl_price = entry_price - sl_pips * pip_size
            tp_price = entry_price + tp_pips * pip_size
        else:
            sl_price = entry_price + sl_pips * pip_size
            tp_price = entry_price - tp_pips * pip_size

        return {
            "sl_price": round(sl_price, 5),
            "tp_price": round(tp_price, 5),
            "sl_pips": sl_pips,
            "tp_pips": tp_pips,
            "risk_reward_ratio": 2.0,
            "based_on": "DEFAULT",
            "confidence": "LOW",
        }

    # ------------------------------------------------------------------
    # 8Ô∏è‚É£  Utility ‚Äì best trading hours (based on average range & sample size)
    # ------------------------------------------------------------------
    def get_best_trading_hours(self, min_sample_size: int = 50) -> List[int]:
        """
        Return a list of the top‚Äëperforming hours (0‚Äë23) ordered by
        ‚Äúquality‚Äù = avg_range * (samples/100).  Hours with fewer than
        ``min_sample_size`` candles are ignored.
        """
        if not self.hourly_stats:
            # Default to typical European/US session hours
            return list(range(8, 18))

        ranked = []
        for hour_str, stats in self.hourly_stats.items():
            total_candles = stats.get("total_candles", 0)
            if total_candles < min_sample_size:
                continue

            avg_range = stats.get("total_range_avg_pips", 0)
            hour = int(hour_str.split(":")[0])          # ‚Äú13:00‚Äë13:59‚Äù ‚Üí 13
            quality = avg_range * (total_candles / 100)
            ranked.append({"hour": hour, "quality": quality})

        ranked.sort(key=lambda x: x["quality"], reverse=True)
        return [item["hour"] for item in ranked[:12]]   # top 12 hours

    # ------------------------------------------------------------------
    # 9Ô∏è‚É£  Volatility‚Äëbased position‚Äësize adjustment
    # ------------------------------------------------------------------
    def get_volatility_adjustment(self, volatility_state: str) -> float:
        """
        Return a multiplier that can be applied to the raw position size.

        * HIGH volatility ‚Üí 0.5 (reduce size)
        * LOW  volatility ‚Üí 1.2 (increase size)
        * NORMAL          ‚Üí 1.0
        """
        if not self.overall_stats:
            return 1.0

        state = volatility_state.upper()
        if state not in self.volatility_stats:
            return 1.0

        stats = self.volatility_stats[state]
        avg_range = stats.get("total_range_avg_pips", 0)
        overall_avg = self.overall_stats.get("total_range_avg_pips", 50)

        if avg_range > overall_avg * 1.5:
            return 0.5
        if avg_range < overall_avg * 0.7:
            return 1.2
        return 1.0

    # ------------------------------------------------------------------
    # 10Ô∏è‚É£  Human‚Äëreadable summary (good for logs / Grafana panels)
    # ------------------------------------------------------------------
    def get_statistics_summary(self) -> str:
        """Return a pretty‚Äëprinted multi‚Äësection summary."""
        if self.overall_stats is None:
            return "No statistics loaded"

        s = "\n"
        s += "‚ïê" * 70 + "\n"
        s += "       CANDLESTICK STATISTICS SUMMARY\n"
        s += "‚ïê" * 70 + "\n"

        # Overall
        s += "\nüìä Overall Statistics:\n"
        s += f"   Total candles : {int(self.overall_stats.get('total_candles', 0))}\n"
        s += f"   Bullish %     : {self.overall_stats.get('bullish_pct', 0):.1f}%\n"
        s += f"   Avg body (p)  : {self.overall_stats.get('body_avg_pips', 0):.1f} pips\n"
        s += f"   Avg range (p) : {self.overall_stats.get('total_range_avg_pips', 0):.1f} pips\n"
        s += f"   Max range (p) : {self.overall_stats.get('total_range_max_pips', 0):.1f} pips\n"

        # Hourly
        s += "\n‚è∞ Hourly Statistics:\n"
        s += f"   Hours loaded : {len(self.hourly_stats)}\n"

        # Daily
        s += "\nüìÖ Daily Statistics:\n"
        s += f"   Days loaded  : {len(self.daily_stats)}\n"

        # Volatility
        s += "\nüìä Volatility Statistics:\n"
        for vol, stats in self.volatility_stats.items():
            s += f"   {vol}: {stats.get('total_range_avg_pips', 0):.1f} pips avg\n"

        # Recommendations
        s += "\nüí° Recommendations:\n"
        s += f"   Conservative SL : {self.overall_stats.get('recommended_sl_pips', 0):.1f} pips\n"
        s += f"   Suggested TP (1:2) : {self.overall_stats.get('recommended_tp_pips', 0):.1f} pips\n"

        s += "\n" + "‚ïê" * 70 + "\n"
        return s

    # ------------------------------------------------------------------
    # 11Ô∏è‚É£  Export a ready‚Äëto‚Äëconsume JSON file (e.g. for UI or downstream bots)
    # ------------------------------------------------------------------
    def export_recommendations(self, output_path: str = "sl_tp_recommendations.json") -> bool:
        """
       except Exception as e:   # pragma: no cover
            logger.error(f"‚ùå Export failed: {e}")
            return False

# ----------------------------------------------------------------------
# Global singleton ‚Äì import this from ``src/main.py`` and use it directly
# ----------------------------------------------------------------------
candlestick_analyzer = CandlestickAnalyzer()

# ----------------------------------------------------------------------
# Simple sanity‚Äëcheck / demo when the module is executed directly
# ----------------------------------------------------------------------
def _demo() -> None:
    """
    Run a quick demonstration:
    * Load the CSV (if present)
    * Print a summary
    * Show SL/TP for a few example symbols / directions
    * List the best trading hours
    * Export the JSON recommendation file
    """
    logger.info("=" * 70)
    logger.info("      CANDLESTICK ANALYZER ‚Äì DEMO RUN")
    logger.info("=" * 70)

    if not candlestick_analyzer.load_statistics():
        logger.error("‚ùå Unable to load candlestick statistics ‚Äì aborting demo.")
        logger.info(
            "üí° To generate the CSV, run the MQL5 script "
            "`CandlestickAnalysisReport.mq5` inside MetaTrader‚ÄØ5."
        )
        return

    # ------------------------------------------------------------------
    # 1Ô∏è‚É£  Print a human‚Äëreadable summary
    # ------------------------------------------------------------------
    logger.info("\nüìä Statistics Summary:")
    logger.info(candlestick_analyzer.get_statistics_summary())

    # ------------------------------------------------------------------
    # 2Ô∏è‚É£  Show a few SL/TP calculations
    # ------------------------------------------------------------------
    logger.info("\nüéØ Sample SL/TP calculations")
    logger.info("-" * 60)

    sample_trades = [
        {"symbol": "EURUSD", "direction": "BUY", "entry": 1.0850, "vol": "NORMAL"},
        {"symbol": "GBPUSD", "direction": "SELL", "entry": 1.2650, "vol": "HIGH"},
        {"symbol": "USDJPY", "direction": "BUY", "entry": 150.25, "vol": "LOW"},
    ]

    for tr in sample_trades:
        res = candlestick_analyzer.get_optimal_sl_tp(
            symbol=tr["symbol"],
            direction=tr["direction"],
            entry_price=tr["entry"],
            volatility_state=tr["vol"],
        )
        logger.info(
            f"\n{tr['symbol']} {tr['direction']} @ {tr['entry']:.5f} "
            f"[{tr['vol']} vol]"
        )
        logger.info(
            f"  ‚ûú SL: {res['sl_price']:.5f} ({res['sl_pips']:.1f} pips) | "
            f"TP: {res['tp_price']:.5f} ({res['tp_pips']:.1f} pips) | "
            f"R:R = 1:{res['risk_reward_ratio']:.1f}"
        )
        logger.info(f"  ‚ûú Confidence: {res['confidence']} (based on {res['based_on']})")

    # ------------------------------------------------------------------
    # 3Ô∏è‚É£  Best trading hours (according to historic range & sample size)
    # ------------------------------------------------------------------
    best_hours = candlestick_analyzer.get_best_trading_hours()
    logger.info("\n‚è∞ Best Trading Hours (0‚Äë23):")
    logger.info("-" * 60)
    logger.info(", ".join(f"{h:02d}:00" for h in best_hours))

    # ------------------------------------------------------------------
    # 4Ô∏è‚É£  Export the full recommendation bundle to JSON
    # ------------------------------------------------------------------
    logger.info("\nüíæ Exporting JSON recommendation file ‚Ä¶")
    if candlestick_analyzer.export_recommendations():
        logger.info("‚úÖ Export successful ‚Üí sl_tp_recommendations.json")
    else:
        logger.error("‚ùå Export failed")

    logger.info("\n" + "=" * 70 + "\nDemo finished.\n")


if __name__ == "__main__":
    # When the module is invoked directly, run the demo.
    # In production the bot will import ``candlestick_analyzer`` and call
    # ``get_optimal_sl_tp`` as needed.
    logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")
    _demo()
