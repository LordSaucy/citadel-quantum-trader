# ======================================================================
#  Citadel‚ÄØQuantum‚ÄØTrader ‚Äì Production Docker‚ÄëCompose
# ======================================================================
# This file is **single‚Äësource of truth** for every container that runs
# on the Vultr droplets (engine, DB, monitoring, backup, admin UI, etc.).
# All secrets are injected as Docker secrets ‚Äì they are **not** stored in
# this file.  The `.env` file (checked‚Äëin) contains only static,
# non‚Äësecret defaults (ports, mode flags, etc.).
#
#   ‚Ä¢ Primary & standby engines use the **same compose file** ‚Äì the only
#     difference is the private IP each droplet owns (the Managed Load
#     Balancer points to both).
#   ‚Ä¢ The Managed Load Balancer terminates TLS on port‚ÄØ443 and health‚Äë
#     checks `/healthz` on port‚ÄØ8005.
#   ‚Ä¢ Services that need persistence (PostgreSQL, Prometheus, Grafana,
#     Loki) have named volumes.
#   ‚Ä¢ Optional side‚Äëcars (OTel Collector, Jaeger, Alertmanager, Pushgateway)
#     are included for full observability.
# ======================================================================

version: "3.9"

# ----------------------------------------------------------------------
#  NETWORKS
# ----------------------------------------------------------------------
networks:
  cqt-net:
    driver: bridge

# ----------------------------------------------------------------------
#  VOLUMES (persistent storage)
# ----------------------------------------------------------------------
volumes:
  pg_data:            {}   # PostgreSQL data (NVMe block storage)
  prom_data:          {}   # Prometheus TSDB
  grafana_data:       {}   # Grafana dashboards/plugins
  loki_data:          {}   # Loki log chunks
  backup_scripts:     {}   # Mounts the backup scripts into the backup container
  admin_frontend:     {}   # Built Vite UI (static assets)
  admin_backend:      {}   # FastAPI backend (static files are copied here)
  sentinel:           {}   # Empty volume used only for ‚Äústop_grace_period‚Äù

# ======================================================================
#  SERVICES
# ======================================================================

services:

# ----------------------------------------------------------------------
#  1Ô∏è‚É£  ENGINE (primary‚ÄØ/‚ÄØstandby ‚Äì identical definition)
# ----------------------------------------------------------------------
  engine:
    image: ghcr.io/${GITHUB_REPOSITORY_OWNER:-yourorg}/cqt-engine:${IMAGE_TAG:-latest}
    container_name: cqt-engine
    restart: unless-stopped
    env_file: [.env]                     # static, non‚Äësecret values
    secrets:
      - POSTGRES_PASSWORD
      - CQT_API_TOKEN
      - MT5_PASSWORD
      - IBKR_API_KEY
      - IBKR_SECRET
    ports:
      - "8005:8005"                     # FastAPI control API (exposed to LB)
      - "8000:8000"                     # /metrics endpoint (scraped by Prometheus)
    depends_on:
      - db
    networks:
      - cqt-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8005/healthz"]
      interval: 10s
      timeout: 5s
      retries: 3
    stop_grace_period: 30s               # give the app time to finish pending work

# ----------------------------------------------------------------------
#  2Ô∏è‚É£  POSTGRESQL / TIMESCALEDB (immutable ledger)
# ----------------------------------------------------------------------
  db:
    image: ghcr.io/${GITHUB_REPOSITORY_OWNER:-yourorg}/cqt-db:${IMAGE_TAG:-latest}
    container_name: cqt-db
    restart: unless-stopped
    environment:
      POSTGRES_USER: citadel
      POSTGRES_DB: citadel
      POSTGRES_PASSWORD_FILE: /run/secrets/POSTGRES_PASSWORD
    secrets:
      - POSTGRES_PASSWORD
    ports:
      - "5432:5432"
    volumes:
      - pg_data:/var/lib/postgresql/data
      - ./postgresql.conf:/etc/postgresql/postgresql.conf:ro
      - ./pg_hba.conf:/etc/postgresql/pg_hba.conf:ro
    command: ["postgres", "-c", "config_file=/etc/postgresql/postgresql.conf"]
    networks:
      - cqt-net
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "citadel"]
      interval: 10s
      timeout: 5s
      retries: 5

# ----------------------------------------------------------------------
#  3Ô∏è‚É£  PROMETHEUS (metrics collector)
# ----------------------------------------------------------------------
  prometheus:
    image: prom/prometheus:latest
    container_name: cqt-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./alert_rules.yml:/etc/prometheus/alert_rules.yml:ro
      - prom_data:/prometheus
    networks:
      - cqt-net
    depends_on:
      - engine
      - db
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:9090/-/ready"]
      interval: 15s
      timeout: 5s
      retries: 3

# ----------------------------------------------------------------------
#  4Ô∏è‚É£  ALERTMANAGER (receives alerts from Prometheus)
# ----------------------------------------------------------------------
  alertmanager:
    image: prom/alertmanager:latest
    container_name: cqt-alertmanager
    restart: unless-stopped
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/config.yml:ro
    networks:
      - cqt-net
    depends_on:
      - prometheus

# ----------------------------------------------------------------------
#  5Ô∏è‚É£  PUSHGATEWAY (optional ‚Äì for short‚Äëlived batch jobs)
# ----------------------------------------------------------------------
  pushgateway:
    image: prom/pushgateway:latest
    container_name: cqt-pushgateway
    restart: unless-stopped
    ports:
      - "9091:9091"
    networks:
      - cqt-net

# ----------------------------------------------------------------------
#  6Ô∏è‚É£  GRAFANA (private ‚Äì full‚Äëfeatured UI, auth required)
# ----------------------------------------------------------------------
  grafana-private:
    image: grafana/grafana:latest
    container_name: cqt-grafana-private
    restart: unless-stopped
    ports:
      - "3000:3000"
    env_file: [.env]                     # contains GF_SECURITY_ADMIN_PASSWORD, etc.
    secrets:
      - GF_ADMIN_PASS
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana-provisioning:/etc/grafana/provisioning:ro
    networks:
      - cqt-net
    depends_on:
      - prometheus

      services:
  grafana:
    image: grafana/grafana:10.2.0
    ports:
      - "3000:3000"
    volumes:
      - ./grafana:/etc/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GF_ADMIN_PASS}
      - OKTA_CLIENT_ID=${OKTA_CLIENT_ID}
      - OKTA_CLIENT_SECRET=${OKTA_CLIENT_SECRET}
      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL}
    restart: unless-stopped

# ----------------------------------------------------------------------
#  7Ô∏è‚É£  GRAFANA (public ‚Äì read‚Äëonly, anonymous access)
# ----------------------------------------------------------------------
  grafana-public:
    image: grafana/grafana:latest
    container_name: cqt-grafana-public
    restart: unless-stopped
    ports:
      - "3001:3000"
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Viewer
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - cqt-net

    

# ----------------------------------------------------------------------
#  8Ô∏è‚É£  NGINX REVERSE‚ÄëPROXY (TLS termination for public endpoints)
# ----------------------------------------------------------------------
  nginx-proxy:
    image: nginx:alpine
    container_name: cqt-nginx-proxy
    restart: unless-stopped
    ports:
      - "443:443"                         # public HTTPS
    depends_on:
      - grafana-public
      - grafana-private
      - admin-frontend
    volumes:
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./nginx/certs:/etc/nginx/certs:ro   # fullchain.pem + privkey.pem
    networks:
      - cqt-net

# ----------------------------------------------------------------------
#  9Ô∏è‚É£  ADMIN UI ‚Äì FastAPI backend (exposes /api/*)
# ----------------------------------------------------------------------
  admin-backend:
    build:
      context: ./admin_ui/backend
      dockerfile: Dockerfile
    container_name: cqt-admin-backend
    restart: unless-stopped
    env_file: [.env]
    secrets:
      - CQT_API_TOKEN
    ports:
      - "8006:8000"                       # internal only; LB does not expose it
    volumes:
      - admin_backend:/app/static          # static files served by FastAPI
    networks:
      - cqt-net
    depends_on:
      - engine

# ----------------------------------------------------------------------
#  üîü  ADMIN UI ‚Äì Vite SPA (built into `admin_backend` static dir)
# ----------------------------------------------------------------------
  admin-frontend:
    build:
      context: ./admin_ui/frontend
      dockerfile: Dockerfile
    container_name: cqt-admin-frontend
    restart: unless-stopped
    # In production the built assets are copied into `admin-backend` via the
    # multi‚Äëstage Dockerfile, so this service is only needed for local dev.
    # It is kept here for completeness.
    ports:
      - "5173:5173"
    networks:
      - cqt-net

# ----------------------------------------------------------------------
#  1Ô∏è‚É£1Ô∏è‚É£  BACKUP SERVICE (snapshot + log archive)
# ----------------------------------------------------------------------
  backup:
    image: ghcr.io/${GITHUB_REPOSITORY_OWNER:-yourorg}/cqt-backup:${IMAGE_TAG:-latest}
    container_name: cqt-backup
    restart: unless-stopped
    environment:
      DO_TOKEN: ${DO_PAT}
      AWS_ACCESS_KEY_ID: ${DO_SPACES_KEY}
      AWS_SECRET_ACCESS_KEY: ${DO_SPACES_SECRET}
    volumes:
      - pg_data:/srv/pg_data:ro            # read‚Äëonly DB volume
      - ./logs:/srv/logs:ro                # host logs (will be tarred & uploaded)
    networks:
      - cqt-net
    # No public ports ‚Äì the container only talks outbound to DigitalOcean API / Spaces.

# ----------------------------------------------------------------------
#  1Ô∏è‚É£2Ô∏è‚É£  LOKI (log aggregation) + PROMTAIL (ship logs)
# ----------------------------------------------------------------------
  loki:
    image: grafana/loki:2.9.5
    container_name: cqt-loki
    restart: unless-stopped
    ports:
      - "3100:3100"
    volumes:
      - ./loki/local-config.yaml:/etc/loki/local-config.yaml:ro
      - loki_data:/loki
    networks:
      - cqt-net

  promtail:
    image: grafana/promtail:2.9.5
    container_name: cqt-promtail
    restart: unless-stopped
    command: ["-config.file=/etc/promtail/promtail.yaml"]
    volumes:
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - ./promtail/promtail.yaml:/etc/promtail/promtail.yaml:ro
    networks:
      - cqt-net
    depends_on:
      - loki

# ----------------------------------------------------------------------
#  1Ô∏è‚É£3Ô∏è‚É£  OPENTELEMETRY COLLECTOR (OTLP ingestion)
# ----------------------------------------------------------------------
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.106.0
    container_name: cqt-otel-collector
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./otel/otel-collector-config.yaml:/etc/otel-collector-config.yaml:ro
    ports:
      - "4318:4318"   # OTLP HTTP receiver (used by the engine)
    networks:
      - cqt-net
    depends_on:
      - jaeger

# ----------------------------------------------------------------------
#  1Ô∏è‚É£4Ô∏è‚É£  JAEGER (distributed tracing)
# ----------------------------------------------------------------------
  jaeger:
    image: jaegertracing/all-in-one:1.53
    container_name: cqt-jaeger
    environment:
      - COLLECTOR_ZIPKIN_HTTP_PORT=9411
    ports:
      - "6831:6831/udp"   # UDP receiver (JaegerExporter)
      - "16686:16686"     # UI
    networks:
      - cqt-net

# ----------------------------------------------------------------------
#  1Ô∏è‚É£5Ô∏è‚É£  SENTIMENT INGESTOR (optional side‚Äëcar)
# ----------------------------------------------------------------------
  sentiment:
    build:
      context: ./sentiment
      dockerfile: Dockerfile
    container_name: cqt-sentiment
    restart: unless-stopped
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      - redis
    networks:
      - cqt-net

  redis:
    image: redis:7-alpine
    container_name: cqt-redis
    command: ["redis-server", "--save", "60", "1", "--loglevel", "warning"]
    volumes:
      - redis-data:/data
    networks:
      - cqt-net
    restart: unless-stopped

# ----------------------------------------------------------------------
#  1Ô∏è‚É£6Ô∏è‚É£  CORRELATION MATRIX EXPORTER (daily job)
# ----------------------------------------------------------------------
  correlation-exporter:
    image: python:3.11-slim
    container_name: cqt-corr-exporter
    command: ["python", "/opt/cqt/src/correlation_exporter.py"]
    volumes:
      - ./src:/opt/cqt/src:ro
      - ./config:/opt/cqt/config:ro
    environment:
      - DB_URL=${POSTGRES_URL}
    depends_on:
      - db
    networks:
      - cqt-net
    restart: "no"   # run‚Äëonce via a host‚Äëlevel cron or systemd timer

# ----------------------------------------------------------------------
#  1Ô∏è‚É£7Ô∏è‚É£  OPTIONAL: DAILY CALENDAR FETCH (systemd timer runs inside container)
# ----------------------------------------------------------------------
  calendar-fetch:
    image: ghcr.io/${GITHUB_REPOSITORY_OWNER:-yourorg}/cqt-engine:${IMAGE_TAG:-latest}
    container_name: cqt-calendar-fetch
    entrypoint: ["/usr/local/bin/fetch_events.py"]
    restart: "no"
    depends_on:
      - engine
    environment:
      - POSTGRES_URL=${POSTGRES_URL}
    networks:
      - cqt-net

# ----------------------------------------------------------------------
#  1Ô∏è‚É£8Ô∏è‚É£  OPTIONAL: SHADOW‚ÄëMODE CONTROLLER (toggles shadow mode at runtime)
# ----------------------------------------------------------------------
  shadow-controller:
    image: ghcr.io/${GITHUB_REPOSITORY_OWNER:-yourorg}/cqt-engine:${IMAGE_TAG:-latest}
    container_name: cqt-shadow-ctl
    command: ["python", "-c", "from utils.config_watcher import reload_config; reload_config()"]
    restart: "no"
    depends_on:
      - engine
    networks:
      - cqt-net

# ======================================================================
#  SECRETS (created externally on each droplet)
# ======================================================================
secrets:
  POSTGRES_PASSWORD:
    external: true
  CQT_API_TOKEN:
    external: true
  MT5_PASSWORD:
    external: true
  IBKR_API_KEY:
    external: true
  IBKR_SECRET:
    external: true
  GF_ADMIN_PASS:
    external: true

# ======================================================================
#  END OF FILE
# ======================================================================
